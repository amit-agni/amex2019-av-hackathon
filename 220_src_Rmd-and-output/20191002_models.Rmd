---
title: "Data Prep and Model"
author: "Amit Agni"
date: "28/09/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if(!require(pacman)) { install.packages("pacman"); library(pacman)}
p_load(data.table,tidyverse,tictoc,lubridate,here)
p_load(janitor,DataExplorer)
p_load(caret,googledrive,xgboost,DiagrammeR,rBayesianOptimization,GA,ROCR,PRROC)


#remove scientific notation in printing 
options(scipen=999) 
#Revert back : options(scipen=0) 
source(here::here("210_src_R-scripts-functions","functions","misc_functions.R"))
source(here::here("210_src_R-scripts-functions","functions","db_functions.R"))
source(here::here("210_src_R-scripts-functions","functions","to_na.R"))
rm(list = ls())
gc()


```


# See the metric is AUC, so the best you can get from AUC is by submitting probabilities (edited) 
# Selling Price : Final sales value after discount.


### Data Load

```{r}
filenames <- list.files(here('100_data_raw-input'),pattern = '*.csv')

###Load all files
for(i in filenames){
    ##data frame name with only the census table names
    df_name <- strsplit(i,"\\.")[[1]][1]
    assign(df_name, fread(here("100_data_raw-input",i)))
}


table(train$redemption_status)
77640/729


#Basic prep
campaign_data[,`:=`(start_date = lubridate::dmy(start_date)
                   ,end_date = lubridate::dmy(end_date))]

customer_transaction_data[,date := ymd(date)]

customer_demographics[marital_status == '',marital_status:= 'Not disclosed']
customer_demographics[no_of_children == '', no_of_children:= 'maybeNA']
customer_demographics$rented <- as.factor(customer_demographics$rented)

str(customer_demographics)
table(customer_demographics$income_bracket)
plot_histogram(customer_demographics$income_bracket)
customer_demographics[,income_bracket := if_else(income_bracket %in% c(8,9,10,11,12),7L,income_bracket)]

#xgb softmax needs class to start from 0
customer_demographics[,income_bracket := income_bracket - 1]
#customer_demographics$income_bracket <- as.factor(customer_demographics$income_bracket)


#Club some of the item categories
item_data[,.N,category][order(-N)][N<385]$category
item_data[category %in% item_data[,.N,category][order(-N)][N<385]$category
          ,category := 'Miscellaneous']
table(item_data$category)

```


Missing income bracket
```{r}

cust_income <- customer_demographics[,.(customer_id,income_bracket)]

train_test_cust <- unique(unique(train$customer_id)
                         ,unique(test$customer_id))

#customer_transaction_data[,sum(selling_price),strftime(date,format = "01-%m-%y")]

cust_tran <- customer_transaction_data[date >= '2012-06-01' & customer_id %in% train_test_cust]
cust_tran[,`:=`(
  FE_isBOM = if_else(date == floor_date(date,'month'),'Y','N')
  ,FE_isEOM = if_else(date == ceiling_date(date,'month')-1,'Y','N')
  ,FE_isWE = if_else(wday(date,week_start=1) %in% c(6,7),'Y','N'))]

                                      
DT <- merge(cust_tran
            ,cust_income
            ,by = 'customer_id'
            ,all.x = TRUE)

DT <- merge(DT
            ,item_data[,.(item_id,brand_type,category)]
            ,by = 'item_id'
            ,all.x = TRUE)


#Avg selling price at different levels
#one by one
DT_dcast <- data.table()
for(i in c("FE_isWE","FE_isBOM","FE_isEOM","brand_type","category")){
    DT_dcast  <- cbind(DT_dcast
                             ,dcast(DT
                                    ,customer_id + income_bracket ~ paste0(i,"_",get(i))
                                    ,value.var = "selling_price"
                                    ,fun.aggregate = function(x)
                                      avg_tran_price = sum(x,na.rm = TRUE)/length(x)
                                    )
                       )
    
}

cid <- DT_dcast$customer_id
incbrk <- DT_dcast$income_bracket

DT_dcast <- DT_dcast[,-c("customer_id","income_bracket")]

DT_dcast$customer_id <- cid
DT_dcast$income_bracket <- incbrk

DT_dcast <- DT_dcast[,lapply(.SD,to_na),.SDcols = cols]


# # Average sellling price 
# DT[!is.na(income_bracket),.(selling_price=sum(selling_price)/length(item_id))
#    ,.(customer_id,income_bracket)] %>%
#   ggplot(aes(x=factor(income_bracket),y=selling_price,group = income_bracket)) +
#   geom_boxplot() +
#   coord_cartesian(ylim = c(0,200))
# 
# # Average sellling price  over weekend
# DT[!is.na(income_bracket),.(selling_price=sum(selling_price)/length(item_id))
#    ,.(customer_id,income_bracket,FE_isWE)] %>%
#   ggplot(aes(x=factor(income_bracket),y=selling_price,group = income_bracket)) +
#   geom_boxplot() +
#   coord_cartesian(ylim = c(0,200)) +
#   facet_wrap(~FE_isWE)
  



```


run xgb
```{r}



DT <- DT_dcast[!is.na(income_bracket)]

str(DT)
DT <- DT[,-"customer_id"]



index <- createDataPartition(y=DT$income_bracket, p=0.8, list=FALSE) 
my_train <- DT[index,]
my_test <- DT[-index,]

table(my_train$income_bracket)

my_train_labels <- my_train$income_bracket
my_train$income_bracket <- NULL

my_test_labels <- my_test$income_bracket
my_test$income_bracket <- NULL

dummies <- dummyVars(~., data = my_train, fullRank = TRUE)
my_train <- predict(dummies, newdata = my_train)

dummies <- dummyVars(~., data = my_test,fullRank = TRUE)
my_test <- predict(dummies, newdata = my_test)
#my_test_4xgb_explainer <- my_test

my_train <- xgb.DMatrix(my_train, label = my_train_labels)
my_test <- xgb.DMatrix(my_test, label = my_test_labels)

watchlist <- list(train = my_train, test = my_test)


### Manual
xgb_model <- xgb.train(
    params = list(
             booster = "gbtree"
            ,objective = "multi:softprob"
            #,objective = "reg:logistic"
            ,eval_metric = "mlogloss"
            ,num_class = length(unique(DT$income_bracket))
        ,eta = 0.01
        ,max_depth=4
        #,gamma = 0
        ,min_child_weight = 100
 #       ,subsample = 0.3
#        ,colsample_bytree = 0.7
        #,alpha = 0.5
        #,scale_pos_weight = 77.9011
        #,max_delta_step = 3
        )
,data = my_train
,watchlist = watchlist
,nrounds = 1000
,early_stopping_rounds = 50
,verbose = TRUE
,prediction = TRUE) 


# Plot learning curve
ggplot(melt(xgb_model$evaluation_log,
       measure.vars = c("train_mlogloss","test_mlogloss"))) +
    geom_line(aes(x=iter, y=value, color=variable)) 
    #scale_y_continuous(limits = c(0.96,1))  





```

predict test
```{r}

my_train <- DT_dcast[!is.na(income_bracket)]
my_train <- my_train[,-c("customer_id")]

my_train_labels <- my_train$income_bracket
my_train$income_bracket <- NULL

dummies <- dummyVars(~., data = my_train, fullRank = TRUE)
my_train <- predict(dummies, newdata = my_train)

my_train <- xgb.DMatrix(my_train, label = my_train_labels)

xgb_model <- xgboost(
   params = list(
             booster = "gbtree"
            ,objective = "multi:softprob"
            #,objective = "reg:logistic"
            ,eval_metric = "mlogloss"
            ,num_class = length(unique(DT$income_bracket))
        ,eta = 0.01
        ,max_depth=4
        #,gamma = 0
        ,min_child_weight = 77
#        ,subsample = 0.3
#        ,colsample_bytree = 0.7
        #,alpha = 0.5
        #,scale_pos_weight = 77.9011
        #,max_delta_step = 3
        )
,data = my_train
,nrounds = 430
,early_stopping_rounds = 20
,verbose = TRUE
,prediction = TRUE) 


### predit on test
my_test <- DT_dcast[is.na(income_bracket)]
my_test <- my_test[,-c("customer_id")]
my_test$income_bracket <- NULL

dummies <- dummyVars(~., data = my_test,fullRank = TRUE)
my_test <- predict(dummies, newdata = my_test)

my_test <- xgb.DMatrix(my_test)

pred <- predict(xgb_model,newdata = my_test,reshape = T) 
pred <- data.frame(pred)
colnames(pred) <- seq(0,6,1)

#append
DT_dcast[is.na(income_bracket)]$income_bracket<- as.numeric(colnames(pred)[max.col(pred,ties.method="first")])


customer_demographics <- merge(DT_dcast[,.(customer_id,income_bracket)]
      ,customer_demographics[,-"income_bracket"]
      ,by='customer_id'
      ,all.x = TRUE)




```



```{r}

### Dates Feature Engineering
customer_transaction_data[,`:=`(FE_month = month(date,label = TRUE)
                                ,FE_dow = wday(date,week_start = 1,label = TRUE)
                                ,FE_isWE = if_else(wday(date,week_start=1) %in% c(6,7),'Y','N')
                                ,FE_isBOM = if_else(date == floor_date(date,'month'),'Y','N')
                                ,FE_isEOM = if_else(date == ceiling_date(date,'month')-1,'Y','N')
                                #,FE_WofY = week(date)
                                )]


# ### Discount percentages and binning them
# customer_transaction_data[,`:=`(other_discount_pct = round(100*abs(other_discount)/(selling_price+abs(other_discount)+abs(coupon_discount)),1)
#                             #    ,coupon_discount_pct = round(100*abs(coupon_discount)/(selling_price+abs(other_discount)+abs(coupon_discount)),1)
#                                 )]
# 
# lower_bound <- seq(0,90,10)
# customer_transaction_data$other_discount_pct_lvl <- findInterval(customer_transaction_data$other_discount_pct, lower_bound) -1
# #customer_transaction_data$coupon_discount_pct_lvl <- findInterval(customer_transaction_data$coupon_discount_pct, lower_bound) -1



### Campaign dates FE
# campaign_data[,`:=`(FE_month_st = month(start_date,label = TRUE)
#                                 ,FE_dow_st = wday(start_date,week_start = 1,label = TRUE)
#                                 ,FE_isWE_st = if_else(wday(start_date,week_start=1) %in% c(6,7),'Y','N')
#                                 #,FE_isBOM_st = if_else(start_date == floor_date(start_date,'month'),'Y','N')
#                                 #,FE_isEOM_st = if_else(start_date == ceiling_date(start_date,'month')-1,'Y','N')
#                                 #,FE_WofY_st = week(start_date)
#                                 )]

campaign_data[,`:=`(FE_month_end = month(end_date,label = TRUE)
                                ,FE_dow_end = wday(end_date,week_start = 1,label = TRUE)
                                ,FE_isWE_end = if_else(wday(end_date,week_start=1) %in% c(6,7),'Y','N')
                                ,FE_isBOM_end = if_else(end_date == floor_date(end_date,'month'),'Y','N')
                                ,FE_isEOM_end = if_else(end_date == ceiling_date(end_date,'month')-1,'Y','N')
                                #,FE_WofY_end = week(end_date)
                                )]

campaign_data[,campaign_len := as.numeric(end_date - start_date)]
lower_bound <- seq(1,100,7)
campaign_data$campaign_len_lvl <- findInterval(campaign_data$campaign_len, lower_bound) 
campaign_data$campaign_len <- NULL




```


### Merge all

2 parts 
I : Coupon profile
  * Campaign details
  * dcast of item details
  
II : Customer profile
  * Demographics
  * Transaction summary

```{r}

tic()
#Combine train and test
train$flag <- 'TRAIN'
test$flag <- 'TEST'
test$redemption_status <- NA
train_test <- rbind(train,test)

nrow(train) #78369
nrow(test) #50226
nrow(train_test) #128595


#I : coupon profile
#campaign details
tt_cpn_profile <- merge(train_test
                      ,campaign_data
                      ,by = 'campaign_id'
                      ,all.x = TRUE)

#No missing
#plot_missing(tt_cpn_profile)

#dcast of items
temp <- merge(coupon_item_mapping
                        ,item_data
                        ,by = 'item_id')

#combined
# cpn_item_dcast <- dcast(temp
#                         ,coupon_id ~ category + brand_type
#                         ,value.var = 'item_id'
#                         ,fun.aggregate = length)


#one by one
cpn_item_dcast <- data.table()
for(i in c("brand_type","category")){
    cpn_item_dcast  <- cbind(cpn_item_dcast
                             ,dcast(temp
                                    ,coupon_id ~ paste0(i,"_",get(i))
                                    ,value.var = c("item_id")
                                    ,fun.aggregate = length))
}

cpn_ids <- cpn_item_dcast$coupon_id
cpn_item_dcast <- cpn_item_dcast[,-"coupon_id"]
cpn_item_dcast$coupon_id <- cpn_ids



tt_cpn_profile <- merge(tt_cpn_profile
                        ,cpn_item_dcast
                        ,by = 'coupon_id'
                        ,all.x = TRUE)

# No missing
#plot_missing(tt_cpn_profile) 






# II : Customer profile
tt_cust_profile <- merge(train_test
                         ,customer_demographics
                         ,by='customer_id'
                         ,all.x = TRUE)


#40% missing --- this will need fixing
# plot_missing(tt_cust_profile)
# plot_missing(tt_cust_profile[flag == 'TRAIN'])
# plot_missing(tt_cust_profile[flag == 'TEST'])
# plot_missing(customer_demographics)

# tt_cust_profile[customer_id == 1582]
# customer_demographics[customer_id == 1582]


```

### ignore transaction data for now
```{r }

#merge transactions with item data
tran_item <- merge(customer_transaction_data
                          ,item_data
                          ,by = 'item_id'
                          ,all.x = TRUE)

#Put the campaign dates in customer transaction using date


# Summarise at customer level
temp <- tran_item[,.(item_count = length(item_id)
                     #,tot_sales = sum(selling_price) + sum(abs(other_discount)) + sum(abs(coupon_discount))
                     )
                  ,by=.(customer_id
                            ,FE_month
                            ,FE_dow
                            ,FE_isWE
                            ,FE_isBOM
                            ,FE_isEOM
                            ,brand_type
                            ,category)]

# temp2 <- dcast(temp
#               ,customer_id ~ ...
#               ,value.var = c("item_count","tot_sales","tot_other_discount"))

temp


### dcast one column at time and cbind the results into one DT
temp2 <- data.table()
for(i in names(temp[,-c("customer_id","item_count")])){
    temp2  <- cbind(temp2
                     ,dcast(temp
                            ,customer_id ~ paste0(i,"_",get(i))
                            ,value.var = c("item_count")
                            ,fun.aggregate = sum))
}


cust_ids <- temp2$customer_id
temp2 <- temp2[,-"customer_id"]
temp2$customer_id <- cust_ids

cust_tran_summary <- temp2




### Merge transaction summary with cust profile
tt_cust_profile <- merge(tt_cust_profile
                         ,cust_tran_summary
                         ,by = 'customer_id')


```

```{r}

# III MERGE Coupon and Customer data
DT <- merge(tt_cpn_profile
            ,tt_cust_profile
            ,by =c("customer_id"
                   ,"id"
                   ,"campaign_id"
                   ,"coupon_id"
                   ,"redemption_status"
                   ,"flag"))




DT <- DT %>% mutate_if(is.character,as.factor) %>% setDT()
str(DT)

DT_bkup <- copy(DT)

toc()
table(DT$flag,DT$redemption_status)

DT <- DT_bkup

names(DT)

```




```{r}

#which(lapply(DT,nlevels)==1) == TRUE

#remove the id columns
DT <- DT[,-c("customer_id","id","campaign_id","coupon_id","start_date","end_date")]

str(DT)



DT <- DT[flag == "TRAIN",]
DT$flag <- NULL


index <- createDataPartition(y=DT$redemption_status, p=0.8
                             , list=FALSE) 
my_train <- DT[index,]
my_test <- DT[-index,]

table(my_train$redemption_status)
62092/604


my_train_labels <- my_train$redemption_status
my_train$redemption_status <- NULL

my_test_labels <- my_test$redemption_status
my_test$redemption_status <- NULL

dummies <- dummyVars(~., data = my_train, fullRank = TRUE)
my_train <- predict(dummies, newdata = my_train)

dummies <- dummyVars(~., data = my_test,fullRank = TRUE)
my_test <- predict(dummies, newdata = my_test)
#my_test_4xgb_explainer <- my_test

my_train <- xgb.DMatrix(my_train, label = my_train_labels)
my_test <- xgb.DMatrix(my_test, label = my_test_labels)

watchlist <- list(train = my_train, test = my_test)


```


elapsed = 52.80	Round = 94	max_depth = 3.0000	gamma = 0.0000	colsample_bytree = 0.3684	max_delta_step = 10.8719	min_child_weight = 25.0000	subsample = 0.9000	Value = 0.9090 

elapsed = 66.30	Round = 82	max_depth = 4.0000	gamma = 2.2197	colsample_bytree = 0.5239	max_delta_step = 9.6281	min_child_weight = 1.0000	subsample = 0.9000	Value = 0.9233 

elapsed = 59.56	Round = 59	max_depth = 5.0000	gamma = 0.0000	colsample_bytree = 0.3949	max_delta_step = 2.7728	min_child_weight = 9.0000	subsample = 0.4180	Value = 0.9237 



Manual parameters
```{r}


xgb_model <- xgb.train(
    params = list(
             booster = "gbtree"
            ,objective = "binary:logistic"
            #,objective = "reg:logistic"
            ,eval_metric = "auc"
        ,eta = 0.01
        ,max_depth=5
        #,gamma = 2.2197
        ,colsample_bytree = 0.2
        ,max_delta_step =15
        ,min_child_weight = 30
        ,subsample = 0.2
        #,alpha = 0.5
        #,scale_pos_weight = 77.9011
        )
,data = my_train
,watchlist = watchlist
,nrounds = 300
,early_stopping_rounds = 50
,verbose = TRUE
,prediction = TRUE) 



# Plot learning curve
ggplot(melt(xgb_model$evaluation_log,
       measure.vars = c("train_auc","test_auc"))) +
    geom_line(aes(x=iter, y=value, color=variable)) 
    #scale_y_continuous(limits = c(0.96,1))  

# Feature importance
importance <- xgb.importance(model = xgb_model)
importance[1:30]
xgb.plot.importance(importance[1:30])


#Predict on test
pred <- predict(xgb_model,newdata = my_test) 
summary(pred)
plot_histogram(pred)

# Learning : Manually updated the probs and see the impact on the curves
pred <- data.table(pred=pred,my_test_labels=my_test_labels)[
  my_test_labels==1,pred:=pred*1.2]$pred

### ROCR Optimal cutoff
fg <- pred[my_test_labels == 1]
bg <- pred[my_test_labels == 0]

roc_curve <- roc.curve(scores.class0 = fg, scores.class1 = bg, curve = T,max.compute = TRUE,min.compute = TRUE)
roc_curve
plot(roc_curve)

pr_curve <- pr.curve(scores.class0 = fg, scores.class1 = bg, curve = T,max.compute = TRUE,min.compute = TRUE)
pr_curve
plot(pr_curve)

table(pred = ifelse(pred>0.05,1,0),actual=my_test_labels)


# Calculate AUC 
rocr_pred <- prediction(labels = my_test_labels,predictions = ifelse(pred>0.05,1,0))
perf.auc <- performance(rocr_pred, measure = "auc")
unlist(perf.auc@y.values)

perf <- performance(rocr_pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC curve",
     col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)



```



Bayesian
```{r}

# Test has to be second in the list else, XGB uses train metric for early stopping
# watchlist <- list(train = my_train,test = my_test)


opt_fn <- function(max_depth,gamma,colsample_bytree,max_delta_step,min_child_weight,subsample) {
    xgb_model <- xgb.train(
        params = list(
            booster = "gbtree"
            ,objective = "binary:logistic"
            ,eval_metric = "auc"
            ,eta = 0.1
            ,max_depth=max_depth
            ,gamma = gamma
            ,colsample_bytree=colsample_bytree
            ,max_delta_step=max_delta_step
            ,min_child_weight=min_child_weight
            ,subsample=subsample)
    ,data = my_train
    ,watchlist = watchlist
    ,nrounds = 150
    ,early_stopping_rounds = 10
    ,verbose = TRUE
    ,prediction = TRUE) 
    
    print(xgb_model$evaluation_log)
    
    ggplot(melt(xgb_model$evaluation_log,
       measure.vars = c("train_auc","test_auc"))) +
    geom_line(aes(x=iter, y=value, color=variable)) %>%
      print()
    
    list(#Score = xgb_model$best_score
        Score = xgb_model$evaluation_log[xgb_model$best_iteration]$test_auc 
        # For Regression minimise rmse
        #Score = -xgb_model$evaluation_log[xgb_model$best_iteration]$test_rmse
        ,Pred = xgb_model$pred)
}


opt_res <- BayesianOptimization(opt_fn
                                ,bounds = list(
                                  #  nrounds = 150
                                  #  ,eta = 0.1
                                    max_depth = c(3L,5L)
                                    ,gamma = c(0,200)
                                    ,colsample_bytree = c(0.1,0.9)
                                    ,max_delta_step = c(1,15)
                                    ,min_child_weight=c(1L,100L)
                                    ,subsample = c(0.1,0.9))
                                ,init_grid_dt = NULL
                                ,init_points = 10
                                ,n_iter = 250
                                ,acq = "ucb"
                                ,kappa = 2.576
                                #,eps = 2
                                ,verbose = TRUE)




```



### Train on whole train and submission


```{r}


my_train <- DT_bkup[flag == "TRAIN",]

my_train <- my_train[,-c("customer_id","id","campaign_id","coupon_id","start_date","end_date")]
my_train$flag <- NULL

my_train_labels <- my_train$redemption_status
my_train$redemption_status <- NULL

dummies <- dummyVars(~., data = my_train, fullRank = TRUE)
my_train <- predict(dummies, newdata = my_train)

my_train <- xgb.DMatrix(my_train, label = my_train_labels)

xgb_model <- xgboost(
    params = list(
             booster = "gbtree"
            ,objective = "binary:logistic"
            #,objective = "binary:hinge"
            
            ,eval_metric = "auc"
        ,eta = 0.01
        ,max_depth=5
        #,gamma = 2.2197
        ,colsample_bytree = 0.2
        ,max_delta_step =15
        ,min_child_weight = 30
        ,subsample = 0.2
        #,alpha = 0.5
        #,scale_pos_weight = 77.9011
        )
,data = my_train
,nrounds = 150
,early_stopping_rounds = 15
,verbose = TRUE
,prediction = TRUE) 


### submission
my_test <- DT_bkup[flag == "TEST",]
my_test <- my_test[,-c("customer_id","id","campaign_id","coupon_id","start_date","end_date")]
my_test$flag <- NULL
my_test$redemption_status <- NULL

dummies <- dummyVars(~., data = my_test,fullRank = TRUE)
my_test <- predict(dummies, newdata = my_test)

my_test <- xgb.DMatrix(my_test)

pred <- predict(xgb_model,newdata = my_test) 
summary(pred)
plot_histogram(pred)


#pred <- ifelse(pred>0.03,1,0)


```


Submission
```{r}

#get_unique_ids <- fread(here::here("100_data_raw-input","test.csv"))

submit_kaggle <- as.data.frame(cbind(test$id,pred))
colnames(submit_kaggle) <- c("id"
                             ,"redemption_status")

write.csv(submit_kaggle
          ,file = here("300_output"
                       ,paste0(strftime(Sys.time(), format="%Y%m%d_%H%M%S"),"_submit_XGB_",".csv"))
          ,row.names = FALSE)


```



Evaluation
```{r}

p_load(ROCR)
pred <- prediction(labels = test_set$target,
                   predictions = ifelse(prob_pred>0.1,1,0))
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC curve",
     col = "blue", lwd = 3)
abline(a = 0, b = 1, lwd = 2, lty = 2)
perf.auc <- performance(pred, measure = "auc")
unlist(perf.auc@y.values)

#[1] 0.5083798 (0.95 split)
#[1] 0.507306 (0.75 split)

perf.f <- performance(pred,measure ="f")
unlist(perf.f@y.values)
#[1]        NaN 0.04014870 0.07034948
#[1]        NaN 0.03711442 0.07032977





p_load(PRROC)
fg <- predict.0$`1`[test$is_attributed == 1]
bg <- predict.0$`1`[test$is_attributed == 0]
# ROC Curve    
roc <- roc.curve(scores.class0 = fg, scores.class1 = bg, curve = T)
plot(roc)
# PR Curve
pr <- pr.curve(scores.class0 = fg, scores.class1 = bg, curve = T)
plot(pr)
test$predicted <- ifelse(predict.0$`1` > 0.75,1,0)
table(pred = test$predicted,actual=test$is_attributed)


```




### Old code
```{r}

names(tt_cpn_profile)
names(tt_cust_profile)

tran_cpn_item <- merge(tran_item
                       ,coupon_item_mapping
                       ,by = 'item_id'
                       ,all.x = TRUE
                       ,allow.cartesian = TRUE)


#final merge
DT <- merge(tt_cpn_item
              ,tran_cpn_item
              ,by = c('customer_id','coupon_id','item_id')
              ,all.x = TRUE) %>%
  setDT()

#Remove everything except temp
#rm(list = ls()[ls() != "DT"])
gc()

DT_non_campaign <- DT[is.na(date)]
DT <- DT[!is.na(date)]


temp <- copy(DT)
#DT<-temp

toc()

```


### Process
```{r}

DT[,`:=`(start_date = lubridate::dmy(start_date)
         ,end_date = lubridate::dmy(end_date)
         ,date = lubridate::ymd(date))]

DT[marital_status == '',marital_status:= 'Not disclosed']
DT[no_of_children == '', no_of_children:= 'maybeNA']

DT <- DT %>% mutate_if(is.character,as.factor) %>% setDT()

DT$income_bracket <- as.factor(DT$income_bracket)
DT$rented <- as.factor(DT$rented)

str(DT)

get_dupes(DT[,.N,.(id,coupon_id,campaign_id,customer_id)])


table(DT$flag,DT$redemption_status)


DT[,is_date_bet := if_else(date>=start_date & date <= end_date,'Y','N')]

```



### Process 
```{r}
str(campaign_data)
#get_dupes(campaign_data,campaign_id)

campaign_data[,`:=`(start_date = lubridate::dmy(start_date)
                   ,end_date = lubridate::dmy(end_date)
                   ,start_end = interval(start_date,end_date))]


plot_bar(campaign_data)
plot_histogram(campaign_data)

min(campaign_data$start_date)
max(campaign_data$end_date)


#Campaigns run for
t(t(table(campaign_data$end_date - campaign_data$start_date)))


# #TO DO : use rolling joins to see if there are any interval overalaps
# campaign_data[,start_end := lubridate::interval(start_date,end_date)]
# 
# all_intervals <- campaign_data$start_end
# int1 <- campaign_data$start_end[1]
# int1 == campaign_data$start_end 
# length(which(int1 %within% all_intervals == TRUE))
# 
# campaign_data$is_bet_any_other <- NULL
# campaign_data[,is_bet_any_other := length(which(start_end %within% all_intervals[start_end != all_intervals] == TRUE))]



```

### Customer demographics
```{r}
str(customer_demographics)
# get_dupes(customer_demographics)
# get_dupes(customer_demographics,customer_id)


customer_demographics[customer_demographics == ''] <- NA

customer_demographics <- customer_demographics %>%
    mutate_if(is.character,as.factor)

plot_bar(customer_demographics)
plot_histogram(customer_demographics)

plot_missing(customer_demographics)



```


### Item data
```{r}
str(item_data)

plot_bar(item_data)
plot_histogram(item_data)

item_data <- item_data %>% mutate_if(is.character,as.factor)

plot_correlation(item_data[,-1])

get_dupes(item_data,item_id)


```


### Coupon Item

```{r}

str(coupon_item_mapping)
plot_histogram(coupon_item_mapping)
#get_dupes(coupon_item_mapping)

head(get_dupes(coupon_item_mapping,coupon_id))
head(get_dupes(coupon_item_mapping,item_id))


```


### Customer transaction

```{r fig.width=12}
str(customer_transaction_data)

plot_histogram(customer_transaction_data)

#unique(customer_transaction_data$date)
customer_transaction_data[,date := ymd(date)]

min(customer_transaction_data$date)
max(customer_transaction_data$date)

customer_transaction_data[,.(sale_amt = sum(selling_price,na.rm = TRUE))
                          ,.(date)] %>%
    ggplot() +
    geom_line(aes(x=date,y=sale_amt)) +
    scale_x_date(date_breaks = "weeks") +
    theme_minimal() +
    theme(plot.title=element_text(size=13, hjust=-0.05,colour="royalblue4", face = "bold")
    ,legend.position = "bottom"
    ,legend.title = element_text(colour="royalblue3")
    ,legend.text = element_text(colour="grey30")
    ,axis.text.x = element_text(angle = 45, hjust = 1,size=7)
    ,axis.title.x = element_text(colour="royalblue3")
    ,axis.title.y = element_text(colour="royalblue3")
    ,axis.ticks = element_line(color = "grey60")
    ,axis.line = element_blank()
    ,panel.background = element_rect(fill = "grey98")
    ,panel.grid.minor = element_blank())


customer_transaction_data[,.(sale_amt = sum(selling_price,na.rm = TRUE))
                          ,.(coupon_discount)][order(-sale_amt)]

customer_transaction_data[,.(sale_amt = sum(selling_price,na.rm = TRUE))
                          ,.(coupon_discount)][order(-sale_amt)]

for(i in colnames(customer_transaction_data[,.(quantity,selling_price,other_discount,coupon_discount)])){
    
    print(i)
    head(customer_transaction_data[order(get(i))]) %>% print()
    head(customer_transaction_data[order(-get(i))]) %>% print()
}


```



### Merging data

Transaction --> Item Data (item id)

